import pandas as pd
import datetime
import re
from sqlalchemy import text
from database import DatabaseManager

class PowerDataImporter:
    def __init__(self):
        self.db_manager = DatabaseManager()
        pass

    # ===============================
    # ä¸»å…¥å£ï¼šå¯¼å…¥æ‰€æœ‰sheet
    # ===============================
    def import_power_data(self, excel_file):
        """è‡ªåŠ¨å¯¼å…¥Excelä¸­æ‰€æœ‰Sheetçš„æ•°æ®ï¼Œæ—¥æœŸè‡ªåŠ¨è¯†åˆ«"""
        sheet_dict = self.read_excel_data(excel_file)
        if not sheet_dict:
            return False

        all_records = []

        for sheet_name, df in sheet_dict.items():
            # === è‡ªåŠ¨è¯†åˆ«æ—¥æœŸ ===
            match = re.search(r"\((\d{4}-\d{2}-\d{2})\)", sheet_name)
            data_date = match.group(1) if match else datetime.datetime.now().strftime('%Y-%m-%d')

            # === æ ¹æ®æ–‡ä»¶åè¯†åˆ«ç±»å‹ ===
            file_name = str(excel_file)
            
            chinese_match = re.search(r'([\u4e00-\u9fff]+)', file_name)
            if chinese_match:
                data_type = chinese_match.group(1)
                print(f"ğŸ“ æ–‡ä»¶ç±»å‹è¯†åˆ«: {data_type}")
            else:
                print(f"âš ï¸ æœªèƒ½åœ¨æ–‡ä»¶åä¸­æ‰¾åˆ°æ±‰å­—ï¼š{file_name}ï¼Œè·³è¿‡ã€‚")
                return False

            print(f"\nğŸ“˜ æ­£åœ¨å¤„ç† {sheet_name} | æ—¥æœŸ: {data_date} | ç±»å‹: {data_type}")

            records = self.process_24h_data(df, data_date, sheet_name, data_type)
            all_records.extend(records)

        if not all_records:
            print("âŒ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆæ•°æ®è¢«å¯¼å…¥")
            return False

        # === ä¿å­˜æ•°æ®åº“ ===
        return self.save_to_database(all_records, data_date)

    # ===============================
    # è¯»å–æ‰€æœ‰sheet
    # ===============================
    def read_excel_data(self, excel_file):
        """è¯»å–Excelä¸­æ‰€æœ‰Sheet"""
        try:
            sheet_dict = pd.read_excel(excel_file, sheet_name=None, header=0)
            print(f"âœ… æˆåŠŸè¯»å–Excelï¼Œå…± {len(sheet_dict)} ä¸ªSheet: {list(sheet_dict.keys())}")
            return sheet_dict
        except Exception as e:
            print(f"âŒ è¯»å–Excelå¤±è´¥: {e}")
            return None

    # ===============================
    # å¤„ç†å•ä¸ªsheetçš„24å°æ—¶æ•°æ®
    # ===============================
    def process_24h_data(self, df, data_date, sheet_name, data_type):
        """å¤„ç†å•ä¸ªSheetï¼ˆè¡Œå¼ç»“æ„ï¼‰çš„24å°æ—¶æ•°æ®"""
        records = []

        # æ ‡å‡†åŒ–åˆ—å
        df.columns = [str(c).strip() for c in df.columns]

        # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼šæœ‰"é€šé“åç§°"åˆ—è¿˜æ˜¯æœ‰"ç±»å‹"åˆ—
        if "é€šé“åç§°" in df.columns:
            records = self._process_channel_format(df, data_date, sheet_name, data_type)
        elif "ç±»å‹" in df.columns:
            records = self._process_type_format(df, data_date, sheet_name, data_type)
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° 'é€šé“åç§°' æˆ– 'ç±»å‹' åˆ—ï¼Œè·³è¿‡ã€‚å¯ç”¨åˆ—: {list(df.columns)}")
            return records

        print(f"âœ… {data_type} å¯¼å…¥ {len(records)} æ¡è®°å½•")
        return records

    def _process_channel_format(self, df, data_date, sheet_name, data_type):
        """å¤„ç†æœ‰'é€šé“åç§°'åˆ—çš„æ•°æ®æ ¼å¼"""
        records = []

        # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æœ‰é€šé“åç§°çš„è¡Œ
        valid_rows = df[df["é€šé“åç§°"].notna()]
        if valid_rows.empty:
            print(f"âš ï¸ Sheetä¸­æ— æœ‰æ•ˆé€šé“ï¼Œé€šé“åˆ—å€¼ä¸º: {df['é€šé“åç§°'].unique().tolist()}")
            return records

        # æå–æ‰€æœ‰æ—¶é—´åˆ—ï¼ˆä¸€èˆ¬ä»00:00åˆ°23:45ï¼‰
        time_cols = [c for c in df.columns if re.match(r"\d{2}:\d{2}", c)]
        if not time_cols:
            print(f"âš ï¸ æ²¡æœ‰å‘ç°æ—¶é—´åˆ—: {list(df.columns)}")
            return records

        # éå†æ¯ä¸€è¡Œï¼ˆä¸€ä¸ªé€šé“ï¼‰
        for _, row in valid_rows.iterrows():
            channel_name = row["é€šé“åç§°"]

            for t in time_cols:
                # å¤„ç†NaNå€¼ï¼Œè·³è¿‡NULLå€¼
                value = row[t]
                if pd.isna(value):
                    continue  # è·³è¿‡è¿™ä¸ªè®°å½•
                
                record = {
                    "record_date": data_date,
                    "record_time": t,
                    "channel_name": channel_name,
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)

        return records

    def _process_type_format(self, df, data_date, sheet_name, data_type):
        """å¤„ç†æœ‰'ç±»å‹'åˆ—çš„æ•°æ®æ ¼å¼"""
        records = []

        # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æœ‰ç±»å‹åç§°çš„è¡Œ
        valid_rows = df[df["ç±»å‹"].notna()]
        if valid_rows.empty:
            print(f"âš ï¸ Sheetä¸­æ— æœ‰æ•ˆç±»å‹ï¼Œç±»å‹åˆ—å€¼ä¸º: {df['ç±»å‹'].unique().tolist()}")
            return records

        # æå–æ‰€æœ‰æ—¶é—´åˆ—ï¼ˆä¸€èˆ¬ä»00:00åˆ°23:45ï¼‰
        time_cols = [c for c in df.columns if re.match(r"\d{2}:\d{2}", c)]
        if not time_cols:
            print(f"âš ï¸ æ²¡æœ‰å‘ç°æ—¶é—´åˆ—: {list(df.columns)}")
            return records

        # éå†æ¯ä¸€è¡Œï¼ˆä¸€ä¸ªç±»å‹ï¼‰
        for _, row in valid_rows.iterrows():
            channel_name = row["ç±»å‹"]  # å°†"ç±»å‹"åˆ—çš„å€¼ä½œä¸ºchannel_name

            for t in time_cols:
                # å¤„ç†NaNå€¼ï¼Œè·³è¿‡NULLå€¼
                value = row[t]
                if pd.isna(value):
                    continue  # è·³è¿‡è¿™ä¸ªè®°å½•
                
                record = {
                    "record_date": data_date,
                    "record_time": t,
                    "channel_name": channel_name,
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)

        return records

    # -------------------------------
    # æ•°æ®ä¿å­˜
    # -------------------------------
    def save_to_database(self, records, data_date):
        """ä¿å­˜æ‰€æœ‰Sheetçš„æ•°æ®åˆ°æ•°æ®åº“"""
        if not records:
            print("âŒ æ²¡æœ‰å¯ä¿å­˜çš„è®°å½•")
            return False

        try:
            with self.db_manager.engine.begin() as conn:
                # åˆ é™¤è¯¥æ—¥æœŸæ•°æ®
                delete_stmt = text("""
                    DELETE FROM power_data 
                    WHERE record_date = :record_date
                """)
                conn.execute(delete_stmt, {"record_date": data_date})
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {data_date} çš„æ—§æ•°æ®")

                # æ’å…¥æ–°æ•°æ®
                insert_stmt = text("""
                    INSERT INTO power_data 
                    (record_date, record_time, type, channel_name, value, sheet_name)
                    VALUES (:record_date, :record_time, :type, :channel_name, :value, :sheet_name)
                """)

                batch_size = 200
                for i in range(0, len(records), batch_size):
                    batch = records[i:i + batch_size]
                    conn.execute(insert_stmt, batch)
                    print(f"ğŸ’¾ å·²æ’å…¥ç¬¬ {i // batch_size + 1} æ‰¹æ•°æ® ({len(batch)} æ¡)")

                count_stmt = text("""
                    SELECT COUNT(*) FROM power_data WHERE record_date = :record_date
                """)
                count = conn.execute(count_stmt, {"record_date": data_date}).scalar()
                print(f"âœ… æ•°æ®åº“ä¿å­˜æˆåŠŸ: {count} æ¡è®°å½•")
                return True
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False