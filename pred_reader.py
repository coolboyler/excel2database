import pandas as pd
import datetime
import re
from sqlalchemy import text
from database import DatabaseManager

class PowerDataImporter:
    def __init__(self):
        self.db_manager = DatabaseManager()
        pass

    # ===============================
    # ä¸»å…¥å£ï¼šå¯¼å…¥æ‰€æœ‰sheet
    # ===============================
    def import_power_data(self, excel_file):
        """è‡ªåŠ¨å¯¼å…¥Excelä¸­æ‰€æœ‰Sheetçš„æ•°æ®ï¼Œæ—¥æœŸè‡ªåŠ¨è¯†åˆ«"""
        sheet_dict = self.read_excel_data(excel_file)
        if not sheet_dict:
            return False

        all_records = []

        for sheet_name, df in sheet_dict.items():
            # === è‡ªåŠ¨è¯†åˆ«æ—¥æœŸ ===
            match = re.search(r"\((\d{4}-\d{2}-\d{2})\)", sheet_name)
            data_date = datetime.datetime.strptime(match.group(1), "%Y-%m-%d").date()

            # === æ ¹æ®æ–‡ä»¶åè¯†åˆ«ç±»å‹ ===
            file_name = str(excel_file)
            
            chinese_match = re.search(r'([\u4e00-\u9fff]+)', file_name)
            if chinese_match:
                data_type = chinese_match.group(1)
                print(f"ğŸ“ æ–‡ä»¶ç±»å‹è¯†åˆ«: {data_type}")
            else:
                print(f"âš ï¸ æœªèƒ½åœ¨æ–‡ä»¶åä¸­æ‰¾åˆ°æ±‰å­—ï¼š{file_name}ï¼Œè·³è¿‡ã€‚")
                return False

            print(f"\nğŸ“˜ æ­£åœ¨å¤„ç† {sheet_name} | æ—¥æœŸ: {data_date} | ç±»å‹: {data_type}")

            records = self.process_24h_data(df, data_date, sheet_name, data_type)
            all_records.extend(records)

        if not all_records:
            print("âŒ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆæ•°æ®è¢«å¯¼å…¥")
            return False

        # === ä¿å­˜æ•°æ®åº“ ===
        return self.save_to_database(all_records, data_date)

    # ===============================
    # è¯»å–æ‰€æœ‰sheet
    # ===============================
    def read_excel_data(self, excel_file):
        """è¯»å–Excelä¸­æ‰€æœ‰Sheet"""
        try:
            sheet_dict = pd.read_excel(excel_file, sheet_name=None, header=0)
            print(f"âœ… æˆåŠŸè¯»å–Excelï¼Œå…± {len(sheet_dict)} ä¸ªSheet: {list(sheet_dict.keys())}")
            return sheet_dict
        except Exception as e:
            print(f"âŒ è¯»å–Excelå¤±è´¥: {e}")
            return None

    # ===============================
    # å¤„ç†å•ä¸ªsheetçš„24å°æ—¶æ•°æ®
    # ===============================
    def process_24h_data(self, df, data_date, sheet_name, data_type):
        """å¤„ç†å•ä¸ªSheetï¼ˆè¡Œå¼ç»“æ„ï¼‰çš„24å°æ—¶æ•°æ®"""
        records = []

        # æ ‡å‡†åŒ–åˆ—å
        df.columns = [str(c).strip() for c in df.columns]

        # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼šæœ‰"é€šé“åç§°"åˆ—è¿˜æ˜¯æœ‰"ç±»å‹"åˆ—
        if "é€šé“åç§°" in df.columns:
            records = self._process_channel_format(df, data_date, sheet_name, data_type)
        elif "ç±»å‹" in df.columns:
            records = self._process_type_format(df, data_date, sheet_name, data_type)
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° 'é€šé“åç§°' æˆ– 'ç±»å‹' åˆ—ï¼Œè·³è¿‡ã€‚å¯ç”¨åˆ—: {list(df.columns)}")
            return records

        print(f"âœ… {data_type} å¯¼å…¥ {len(records)} æ¡è®°å½•")
        return records

    def _process_channel_format(self, df, data_date, sheet_name, data_type):
        """å¤„ç†æœ‰'é€šé“åç§°'åˆ—çš„æ•°æ®æ ¼å¼"""
        records = []

        # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æœ‰é€šé“åç§°çš„è¡Œ
        valid_rows = df[df["é€šé“åç§°"].notna()]
        if valid_rows.empty:
            print(f"âš ï¸ Sheetä¸­æ— æœ‰æ•ˆé€šé“ï¼Œé€šé“åˆ—å€¼ä¸º: {df['é€šé“åç§°'].unique().tolist()}")
            return records

        # æå–æ‰€æœ‰æ—¶é—´åˆ—ï¼ˆä¸€èˆ¬ä»00:00åˆ°23:45ï¼‰
        time_cols = [c for c in df.columns if re.match(r"\d{2}:\d{2}", c)]
        if not time_cols:
            print(f"âš ï¸ æ²¡æœ‰å‘ç°æ—¶é—´åˆ—: {list(df.columns)}")
            return records

        # éå†æ¯ä¸€è¡Œï¼ˆä¸€ä¸ªé€šé“ï¼‰
        for _, row in valid_rows.iterrows():
            channel_name = row["é€šé“åç§°"]

            for t in time_cols:
                # å¤„ç†NaNå€¼ï¼Œè·³è¿‡NULLå€¼
                value = row[t]
                if pd.isna(value):
                    continue  # è·³è¿‡è¿™ä¸ªè®°å½•
                
                record = {
                    "record_date": data_date,
                    "record_time": t,
                    "channel_name": channel_name,
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)

        return records

    def _process_type_format(self, df, data_date, sheet_name, data_type):
        """å¤„ç†æœ‰'ç±»å‹'åˆ—çš„æ•°æ®æ ¼å¼"""
        records = []

        # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æœ‰ç±»å‹åç§°çš„è¡Œ
        valid_rows = df[df["ç±»å‹"].notna()]
        if valid_rows.empty:
            print(f"âš ï¸ Sheetä¸­æ— æœ‰æ•ˆç±»å‹ï¼Œç±»å‹åˆ—å€¼ä¸º: {df['ç±»å‹'].unique().tolist()}")
            return records

        # æå–æ‰€æœ‰æ—¶é—´åˆ—ï¼ˆä¸€èˆ¬ä»00:00åˆ°23:45ï¼‰
        time_cols = [c for c in df.columns if re.match(r"\d{2}:\d{2}", c)]
        if not time_cols:
            print(f"âš ï¸ æ²¡æœ‰å‘ç°æ—¶é—´åˆ—: {list(df.columns)}")
            return records

        # éå†æ¯ä¸€è¡Œï¼ˆä¸€ä¸ªç±»å‹ï¼‰
        for _, row in valid_rows.iterrows():
            channel_name = row["ç±»å‹"]  # å°†"ç±»å‹"åˆ—çš„å€¼ä½œä¸ºchannel_name

            for t in time_cols:
                # å¤„ç†NaNå€¼ï¼Œè·³è¿‡NULLå€¼
                value = row[t]
                if pd.isna(value):
                    continue  # è·³è¿‡è¿™ä¸ªè®°å½•
                
                record = {
                    "record_date": data_date,
                    "record_time": t,
                    "channel_name": channel_name,
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)

        return records

    # -------------------------------
    # æ•°æ®ä¿å­˜
    # -------------------------------

    def save_to_database(self, records, data_date):
        """æŒ‰æ—¥æœŸè‡ªåŠ¨åˆ›å»ºè¡¨å¹¶ä¿å­˜æ•°æ®"""
        if not records:
            print("âŒ æ²¡æœ‰å¯ä¿å­˜çš„è®°å½•")
            return False

        # ğŸ§© 1. å¦‚æœä¼ å…¥çš„æ˜¯ DataFrameï¼Œè½¬æˆ list[dict]
        if isinstance(records, pd.DataFrame):
            records = records.to_dict(orient="records")

        if not isinstance(records, list):
            print(f"âŒ records ç±»å‹é”™è¯¯: {type(records)}ï¼Œåº”ä¸º list[dict]")
            return False

        # ğŸ§© 2. è¿‡æ»¤æ— æ•ˆè®°å½•
        valid_records = []
        for i, r in enumerate(records):
            if not isinstance(r, dict):
                continue
            required_fields = ["record_date", "record_time", "channel_name", "value", "type", "sheet_name"]
            if not all(k in r for k in required_fields):
                continue
            # è½¬ record_date
            if isinstance(r["record_date"], str):
                r["record_date"] = pd.to_datetime(r["record_date"]).date()
            valid_records.append(r)

        if not valid_records:
            print("âŒ æ²¡æœ‰å¯ä¿å­˜çš„æœ‰æ•ˆè®°å½•")
            return False

        # --- ç”ŸæˆæŒ‰å¤©è¡¨å ---
        table_name = f"power_data_{data_date.strftime('%Y%m%d')}"

        try:
            with self.db_manager.engine.begin() as conn:
                # --- åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰ ---
                create_table_sql = f"""
                CREATE TABLE IF NOT EXISTS {table_name} (
                    id BIGINT AUTO_INCREMENT PRIMARY KEY,
                    record_date DATE NOT NULL,
                    record_time TIME NOT NULL,
                    type VARCHAR(255),
                    channel_name VARCHAR(255),
                    value DECIMAL(10,2),
                    sheet_name VARCHAR(255)
                );
                """
                conn.execute(text(create_table_sql))
                print(f"âœ… è¡¨ {table_name} å·²å­˜åœ¨æˆ–åˆ›å»ºæˆåŠŸ")

                # --- æ‰¹é‡æ’å…¥ ---
                insert_stmt = text(f"""
                INSERT INTO {table_name} 
                (record_date, record_time, type, channel_name, value, sheet_name)
                VALUES (:record_date, :record_time, :type, :channel_name, :value, :sheet_name)
                """)

                batch_size = 200
                for i in range(0, len(valid_records), batch_size):
                    batch = valid_records[i:i + batch_size]
                    conn.execute(insert_stmt, batch)
                    print(f"ğŸ’¾ å·²æ’å…¥ç¬¬ {i // batch_size + 1} æ‰¹æ•°æ® ({len(batch)} æ¡)")

                count_stmt = text(f"SELECT COUNT(*) FROM {table_name}")
                count = conn.execute(count_stmt).scalar()
                print(f"âœ… æ•°æ®åº“ä¿å­˜æˆåŠŸ: {count} æ¡è®°å½•")
                return True

        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


    def import_custom_excel(self, excel_file):
        """å¯¼å…¥æŒ‡å®šçš„5ä¸ªsheetï¼Œå¹¶æŒ‰å›ºå®šè§„åˆ™æ˜ å°„"""
        try:
            # è¯»å–æ‰€æœ‰sheet
            sheet_dict = pd.read_excel(excel_file, sheet_name=None, header=None)
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–Excel: {e}")
            return False
        file_name = str(excel_file)
        
        chinese_match = re.search(r'([\u4e00-\u9fff]+)', file_name)
        if chinese_match:
            data_type = chinese_match.group(1) + "å®é™…ä¿¡æ¯"
            print(f"ğŸ“ æ–‡ä»¶ç±»å‹è¯†åˆ«: {data_type}")
        else:
            print(f"âš ï¸ æœªèƒ½åœ¨æ–‡ä»¶åä¸­æ‰¾åˆ°æ±‰å­—ï¼š{file_name}ï¼Œè·³è¿‡ã€‚")
            return False
        sheet_names = list(sheet_dict.keys())
        print(f"ğŸ“˜ æ£€æµ‹åˆ° {len(sheet_names)} ä¸ªSheet: {sheet_names}")

        # è¦å¤„ç†çš„sheetç¼–å·ï¼ˆ1-basedï¼‰
        target_indexes = [0, 1, 3, 4, 5]  # å¯¹åº”ç¬¬1,2,4,5,6ä¸ªsheet

        all_records = []

        for i in target_indexes:
            if i >= len(sheet_names):
                print(f"âš ï¸ Excelä¸­ä¸å­˜åœ¨ç¬¬{i+1}ä¸ªsheetï¼Œè·³è¿‡")
                continue

            sheet_name = sheet_names[i]
            df = sheet_dict[sheet_name]
            print(f"\nğŸ”¹ æ­£åœ¨å¤„ç† Sheet {i+1}: {sheet_name}")

            # ç»Ÿä¸€è¯†åˆ«æ—¥æœŸ
            match = re.search(r"\((\d{4}-\d{2}-\d{2})\)", sheet_name)
            data_date = datetime.datetime.strptime(match.group(1), "%Y-%m-%d").date()
            # æ ¹æ®sheetåºå·è°ƒç”¨ä¸åŒæ˜ å°„å‡½æ•°
            if i in [0, 3, 4]:  # ç¬¬1,4,5ä¸ªsheetï¼šæ—¶åˆ»â†’channel_name
                records = self._process_time_as_channel(df, data_date, sheet_name, data_type)
            elif i in [1, 5]:  # ç¬¬2,6ä¸ªsheetï¼šç¬¬ä¸€è¡Œâ†’channel_name
                records = self._process_first_row_as_channel(df, data_date, sheet_name, data_type)
            else:
                print(f"âš ï¸ ç¬¬{i+1}ä¸ªsheetæœªå®šä¹‰å¤„ç†è§„åˆ™ï¼Œè·³è¿‡")
                continue

            print(f"âœ… Sheet{i+1} å¤„ç†å®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•")
            all_records.extend(records)

        if not all_records:
            print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆè®°å½•")
            return False

        return self.save_to_database(all_records, data_date)

    def _process_time_as_channel(self, df, data_date, sheet_name, data_type):
        """å°†æ—¶åˆ»åˆ—åæ˜ å°„ä¸ºchannel_name"""
        records = []
        df = df.dropna(how="all")  # åˆ é™¤ç©ºè¡Œ

        # å¦‚æœç¬¬ä¸€åˆ—æ˜¯ â€œæ—¶åˆ»â€ å­—æ ·
        if str(df.iloc[0, 0]).strip() == "æ—¶åˆ»":
            df.columns = [str(c).strip() for c in df.iloc[0]]  # ç¬¬ä¸€è¡Œä½œåˆ—å
            df = df[1:]  # å»æ‰æ ‡é¢˜è¡Œ
        else:
            df.columns = [str(c).strip() for c in df.columns]

        # æŸ¥æ‰¾æ—¶é—´åˆ—ï¼ˆå½¢å¦‚ 00:00ã€01:15ï¼‰
        time_cols = [c for c in df.columns if re.match(r"\d{2}:\d{2}", c)]
        if not time_cols:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ—¶é—´åˆ—: {df.columns.tolist()}")
            return []

        # éå†æ¯ä¸€è¡Œï¼ˆæ¯ä¸€ç±»æŒ‡æ ‡ï¼‰
        for _, row in df.iterrows():
            # è·³è¿‡æ— æ•ˆè¡Œæˆ–æ ‡é¢˜è¡Œ
            if not isinstance(row[time_cols[0]], (int, float)) and not str(row[time_cols[0]]).replace('.', '', 1).isdigit():
                continue

            # æŒ‡æ ‡åï¼ˆæ¯”å¦‚ â€œç»Ÿè°ƒè´Ÿè·(MW)â€ï¼‰
            indicator_name = str(row.get("æ—¶åˆ»") or row.index[0]).strip()

            for t in time_cols:
                value = row[t]
                if pd.isna(value):
                    continue
                try:
                    value = float(value)
                except:
                    continue  # è·³è¿‡éæ•°å€¼çš„å•å…ƒæ ¼
                record = {
                    "record_date": data_date,
                    "record_time": t,
                    "channel_name": indicator_name,  # ç”¨æŒ‡æ ‡åä½œé€šé“å
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)
        return records

    def _process_first_row_as_channel(self, df, data_date, sheet_name, data_type):
        """
        å¤„ç†æ ¼å¼ï¼š
        æœ€é«˜è´Ÿè·(MW) | æœ€ä½è´Ÿè·(MW) | å¹³å‡è´Ÿè·(MW)
        243330.375    | 182924.0156  | 212967.9509
        """
        records = []
        # åˆ é™¤ç©ºè¡Œä¸ç©ºåˆ—
        df = df.dropna(how="all").dropna(axis=1, how="all")
        if df.empty:
            print(f"âš ï¸ Sheet {sheet_name} ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
            return records

        # ç¬¬ä¸€è¡Œä½œä¸º channel_name
        channel_names = [str(c).strip() for c in df.iloc[0].tolist()]
        df = df.iloc[1:]  # ä»ç¬¬äºŒè¡Œå¼€å§‹ä¸ºæ•°æ®
        if df.empty:
            print(f"âš ï¸ Sheet {sheet_name} ä»…æœ‰è¡¨å¤´ï¼Œæ— æ•°æ®ã€‚")
            return records

        for _, row in df.iterrows():
            for col_idx, value in enumerate(row):
                if col_idx >= len(channel_names):
                    continue
                if pd.isna(value):
                    continue
                record = {
                    "record_date": data_date,
                    "record_time": datetime.datetime.now().time(),  # å…¥åº“æ—¶é—´
                    "channel_name": channel_names[col_idx],
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                }
                records.append(record)

        print(f"âœ… Sheet {sheet_name} è§£æå®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•ã€‚")
        return records

    def import_custom_excel_pred(self, excel_file):
            """å¯¼å…¥æŒ‡å®šçš„5ä¸ªsheetï¼Œå¹¶æŒ‰å›ºå®šè§„åˆ™æ˜ å°„"""
            try:
                # è¯»å–æ‰€æœ‰sheet
                sheet_dict = pd.read_excel(excel_file, sheet_name=None, header=0)
            except Exception as e:
                print(f"âŒ æ— æ³•è¯»å–Excel: {e}")
                return False
            file_name = str(excel_file)
            
            chinese_match = re.search(r'([\u4e00-\u9fff]+)', file_name)
            if chinese_match:
                data_type = chinese_match.group(1) + "é¢„æµ‹ä¿¡æ¯"
                print(f"ğŸ“ æ–‡ä»¶ç±»å‹è¯†åˆ«: {data_type}")
            else:
                print(f"âš ï¸ æœªèƒ½åœ¨æ–‡ä»¶åä¸­æ‰¾åˆ°æ±‰å­—ï¼š{file_name}ï¼Œè·³è¿‡ã€‚")
                return False
            sheet_names = list(sheet_dict.keys())
            print(f"ğŸ“˜ æ£€æµ‹åˆ° {len(sheet_names)} ä¸ªSheet: {sheet_names}")

            # è¦å¤„ç†çš„sheetç¼–å·ï¼ˆ1-basedï¼‰
            target_indexes = [0, 1, 2, -3, -2, -1]  # å¯¹åº”ç¬¬1,2,4,5,6ä¸ªsheet

            all_records = []

            for i in target_indexes:
                if i >= len(sheet_names):
                    print(f"âš ï¸ Excelä¸­ä¸å­˜åœ¨ç¬¬{i+1}ä¸ªsheetï¼Œè·³è¿‡")
                    continue

                sheet_name = sheet_names[i]
                df = sheet_dict[sheet_name]
                print(f"\nğŸ”¹ æ­£åœ¨å¤„ç† Sheet {i+1}: {sheet_name}")

                # ç»Ÿä¸€è¯†åˆ«æ—¥æœŸ
                match = re.search(r"\((\d{4}-\d{2}-\d{2})\)", sheet_name)
                data_date = datetime.datetime.strptime(match.group(1), "%Y-%m-%d").date()

                # æ ¹æ®sheetåºå·è°ƒç”¨ä¸åŒæ˜ å°„å‡½æ•°
                if i in [0]:  # ç¬¬1ä¸ªsheetï¼šæ—¶åˆ»â†’channel_name
                    records = self._process_time_as_channel(df, data_date, sheet_name, data_type)
                elif i in [1]:  # ç¬¬2,6ä¸ªsheetï¼šç¬¬ä¸€è¡Œâ†’channel_name
                    records = self._process_1_channel(df, data_date, sheet_name, data_type)
                elif i in [2]:  # ç¬¬3ä¸ªsheetï¼šæ—¶åˆ»â†’channel_name
                    records = self._process_type_date_value(df, data_date, sheet_name, data_type)
                elif i in [-3]:  # ç¬¬4,5ä¸ªsheetï¼šæ—¶åˆ»â†’channel_name
                    records = self._process_3_channel(df, data_date, sheet_name, data_type)
                elif i in [-2, -1]:  # ç¬¬7,8ä¸ªsheetï¼šç¬¬ä¸€è¡Œâ†’channel_name
                    records = self._process_2_channel(df, data_date, sheet_name, data_type)
                else:
                    print(f"âš ï¸ ç¬¬{i+1}ä¸ªsheetæœªå®šä¹‰å¤„ç†è§„åˆ™ï¼Œè·³è¿‡")
                    continue

                print(f"âœ… Sheet{i+1} å¤„ç†å®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•")
                all_records.extend(records)

            if not all_records:
                print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆè®°å½•")
                return False

            return self.save_to_database(all_records, data_date)
        
    def _process_1_channel(self, df, data_date, sheet_name, data_type):
        """
        å¤šæŒ‡æ ‡æ—¶åˆ»å‹sheetå¤„ç†ï¼š
        - è¯†åˆ«â€œç±»å‹ + ç”µæºç±»å‹â€ä¸º channel_name
        - ä½¿ç”¨â€œæ—¥æœŸâ€åˆ—ä½œä¸º record_date
        - æ—¶é—´åˆ—ä¸º 00:00ã€00:15 ç­‰å¸¸è§„æ ¼å¼
        """
        import datetime
        import pandas as pd
        import re

        records = []
        df = df.dropna(how="all")
        df.columns = [str(c).strip() for c in df.columns]

        # 1ï¸âƒ£ æ‰¾æ—¶é—´åˆ—ï¼ˆå¦‚ 00:00ã€01:15 ç­‰ï¼‰
        time_cols = [c for c in df.columns if re.match(r"^\d{1,2}:\d{2}$", c)]
        if not time_cols:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ—¶é—´åˆ—: {df.columns.tolist()}")
            return []

        # 2ï¸âƒ£ è¯†åˆ«è¾…åŠ©åˆ—
        col_type = "ç±»å‹" if "ç±»å‹" in df.columns else None
        col_date = "æ—¥æœŸ" if "æ—¥æœŸ" in df.columns else None
        col_power = "ç”µæºç±»å‹" if "ç”µæºç±»å‹" in df.columns else None

        # 3ï¸âƒ£ éå†æ¯ä¸€è¡Œï¼ˆæ¯ä¸ªé€šé“ï¼‰
        for _, row in df.iterrows():
            # --- æ—¥æœŸåˆ— ---
            record_date = data_date
            if col_date and pd.notna(row[col_date]):
                try:
                    # è‡ªåŠ¨è¯†åˆ«æ—¥æœŸæ ¼å¼
                    record_date = pd.to_datetime(str(row[col_date]), errors="coerce").date()
                except:
                    record_date = data_date

            # --- é€šé“åï¼šç±»å‹ + ç”µæºç±»å‹ ---
            parts = []
            if col_type and pd.notna(row[col_type]):
                parts.append(str(row[col_type]).strip())
            if col_power and pd.notna(row[col_power]):
                parts.append(str(row[col_power]).strip())
            if not parts:
                continue
            channel_name = "-".join(parts)

            # --- éå†æ—¶é—´åˆ— ---
            for t in time_cols:
                value = row[t]
                if pd.isna(value):
                    continue
                try:
                    value = float(value)
                except:
                    continue

                records.append({
                    "record_date": record_date,        # ç¡®ä¿æ˜¯ date ç±»å‹
                    "record_time": t,                  # å¦‚ 00:00
                    "channel_name": channel_name,      # å¦‚ "ç°è´§æ–°èƒ½æºæ€»å‡ºåŠ›(MW)-é£ç”µ"
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                })

        print(f"âœ… {sheet_name} è§£æå®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•")
        return records

    def _process_3_channel(self, df, data_date, sheet_name, data_type):
        """
        å°†å¤šåˆ—é€šé“å‹Sheetå¤„ç†æˆè®°å½•åˆ—è¡¨ï¼Œæ¯åˆ—è§†ä¸ºä¸€ä¸ªé€šé“ã€‚
        ç»“æ„ç¤ºä¾‹ï¼š
        åºå· | æ—¥æœŸ | å¿…å¼€æœºç»„å®¹é‡(MW) | å¿…åœæœºç»„å®¹é‡(MW)
        """
        import datetime
        import pandas as pd

        print(f"ğŸ”¹ æ­£åœ¨å¤„ç† Sheet: {sheet_name}")

        records = []

        # 1ï¸âƒ£ åˆ é™¤æ— ç”¨åˆ—
        if "åºå·" in df.columns:
            df = df.drop(columns=["åºå·"])

        # 2ï¸âƒ£ ç¡®ä¿æ—¥æœŸå­—æ®µå­˜åœ¨
        if "æ—¥æœŸ" not in df.columns:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œè·³è¿‡ {sheet_name}")
            return []

        df = df.dropna(how="all")
        df.columns = [str(c).strip() for c in df.columns]

        # 3ï¸âƒ£ éå†æ¯ä¸€è¡Œ
        for _, row in df.iterrows():
            # æ—¥æœŸ
            record_date = data_date
            if pd.notna(row["æ—¥æœŸ"]):
                try:
                    record_date = pd.to_datetime(str(row["æ—¥æœŸ"]), errors="coerce").date()
                except:
                    record_date = data_date

            # 4ï¸âƒ£ éå†é€šé“åˆ—ï¼ˆé™¤â€œæ—¥æœŸâ€å¤–ï¼‰
            for col in df.columns:
                if col in ["æ—¥æœŸ"]:
                    continue
                value = row[col]
                if pd.isna(value):
                    continue
                try:
                    value = float(value)
                except:
                    continue

                records.append({
                    "record_date": record_date,
                    "record_time": datetime.datetime.now().time(),
                    "channel_name": col,
                    "value": value,
                    "type": data_type,
                    "sheet_name": sheet_name,
                    "created_at": datetime.datetime.now(),
                })

        print(f"âœ… {sheet_name} å¤„ç†å®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•")
        return records
    
    def _process_2_channel(self, df, data_date, sheet_name, data_type):
        """
        å¤„ç†æœºç»„åå•è¡¨ï¼š
        - channel_name = ç”µå‚åç§°-æœºç»„åç§°-ç±»å‹
        - value é»˜è®¤ä¸º 1
        """
        import datetime
        import pandas as pd

        records = []

        if df.empty:
            print(f"âš ï¸ {sheet_name} è¡¨ä¸ºç©ºï¼Œè·³è¿‡")
            return []

        df = df.dropna(how="all")
        df.columns = [str(c).strip() for c in df.columns]

        # å¿…è¦åˆ—
        col_date = "æ—¥æœŸ" if "æ—¥æœŸ" in df.columns else None
        col_plant = "ç”µå‚åç§°" if "ç”µå‚åç§°" in df.columns else None
        col_unit = "æœºç»„åç§°" if "æœºç»„åç§°" in df.columns else None
        col_type = "ç±»å‹" if "ç±»å‹" in df.columns else None

        for _, row in df.iterrows():
            # æ—¥æœŸ
            record_date = data_date
            if col_date and pd.notna(row[col_date]):
                try:
                    record_date = pd.to_datetime(str(row[col_date]), errors="coerce").date()
                except:
                    record_date = data_date

            # channel_name æ‹¼æ¥
            parts = []
            for col in [col_plant, col_unit, col_type]:
                if col and pd.notna(row[col]):
                    parts.append(str(row[col]).strip())
            if not parts:
                continue
            channel_name = "-".join(parts)

            # æ·»åŠ è®°å½•
            records.append({
                "record_date": record_date,
                "channel_name": channel_name,
                "record_time": datetime.datetime.now().time(),
                "value": 1,
                "type": data_type,
                "sheet_name": sheet_name,
                "created_at": datetime.datetime.now(),
            })

        print(f"âœ… {sheet_name} å¤„ç†å®Œæˆï¼Œå…± {len(records)} æ¡è®°å½•")
        return records

    def _process_type_date_value(self, df, data_date, sheet_name, data_type):
        """å¤„ç†ç±»ä¼¼ 'ç±»å‹ æ—¥æœŸ æ•°å€¼' çš„ç»“æ„ï¼ˆæ— æ—¶é—´åˆ—ï¼Œrecord_dateä¸ºdateç±»å‹ï¼‰"""
        records = []
        df = df.dropna(how="all")
        df.columns = [str(c).strip() for c in df.columns]

        # æŸ¥æ‰¾åˆ—
        col_type = "ç±»å‹" if "ç±»å‹" in df.columns else None
        col_date = "æ—¥æœŸ" if "æ—¥æœŸ" in df.columns else None

        # æŸ¥æ‰¾æ•°å€¼åˆ—ï¼ˆæ’é™¤æ‰å·²çŸ¥åˆ—ï¼‰
        value_cols = [c for c in df.columns if c not in [col_type, col_date]]
        if not value_cols:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ•°å€¼åˆ—: {df.columns.tolist()}")
            return []

        value_col = value_cols[0]  # é»˜è®¤åªå–ç¬¬ä¸€åˆ—æ•°å€¼

        for _, row in df.iterrows():
            channel_name = str(row[col_type]).strip() if col_type else "æœªçŸ¥ç±»å‹"
            raw_date = str(row[col_date]).strip() if col_date and pd.notna(row[col_date]) else None

            # === æ—¥æœŸè§£æé€»è¾‘ ===
            parsed_date = None
            if raw_date:
                # 1. å¦‚æœæ˜¯æ ‡å‡†æ—¥æœŸæ ¼å¼
                try:
                    parsed_date = pd.to_datetime(raw_date).date()
                except Exception:
                    pass

                # 2. å¦‚æœæ˜¯å½¢å¦‚ â€œ2025å¹´ç¬¬38å‘¨(09.15~09.21)â€
                if parsed_date is None:
                    match = re.search(r"\((\d{2})\.(\d{2})", raw_date)
                    year_match = re.search(r"(\d{4})å¹´", raw_date)
                    if match and year_match:
                        year = int(year_match.group(1))
                        month = int(match.group(1))
                        day = int(match.group(2))
                        parsed_date = datetime.date(year, month, day)

            # å¦‚æœéƒ½è§£æå¤±è´¥ï¼Œåˆ™ç”¨ data_date å…œåº•
            if parsed_date is None:
                parsed_date = pd.to_datetime(data_date).date()

            # æ•°å€¼
            try:
                value = float(row[value_col])
            except:
                continue

            record = {
                "record_date": parsed_date,
                "record_time": datetime.datetime.now().time(),
                "channel_name": channel_name,
                "value": value,
                "type": data_type,
                "sheet_name": sheet_name,
                "created_at": datetime.datetime.now(),
            }
            records.append(record)

        return records
    
    def import_point_data(self, excel_file):
        """è‡ªåŠ¨å¯¼å…¥Excelç¬¬ä¸€ä¸ªSheetçš„æ•°æ®ï¼Œå¹¶æŒ‰åˆ—æ±‚å‡å€¼"""
        import re
        import datetime
        import pandas as pd

        try:
            xls = pd.ExcelFile(excel_file)
            first_sheet_name = xls.sheet_names[0]  # âœ… è·å–ç¬¬ä¸€ä¸ª sheet å
            df = pd.read_excel(excel_file, sheet_name=first_sheet_name, header=0)
            print(f"âœ… æˆåŠŸè¯»å– Excel: {excel_file}, sheet: {first_sheet_name}")
        except Exception as e:
            print(f"âŒ è¯»å– Excel å¤±è´¥: {e}")
            return False

        # è‡ªåŠ¨è¯†åˆ«æ—¥æœŸ
        match = re.search(r"\((\d{4}-\d{2}-\d{2})\)", first_sheet_name)
        data_date = datetime.datetime.strptime(match.group(1), "%Y-%m-%d").date()

        # æ ¹æ®æ–‡ä»¶åè¯†åˆ«ç±»å‹
        file_name = str(excel_file)
        chinese_match = re.search(r'([\u4e00-\u9fff]+)', file_name)
        if chinese_match:
            data_type = chinese_match.group(1)
            print(f"ğŸ“ æ–‡ä»¶ç±»å‹è¯†åˆ«: {data_type}")
        else:
            print(f"âš ï¸ æœªèƒ½åœ¨æ–‡ä»¶åä¸­æ‰¾åˆ°æ±‰å­—ï¼š{file_name}ï¼Œè·³è¿‡ã€‚")
            return False

        print(f"\nğŸ“˜ æ­£åœ¨å¤„ç† {first_sheet_name} | æ—¥æœŸ: {data_date} | ç±»å‹: {data_type}")

        # æŒ‰åˆ—æ±‚å‡å€¼å¹¶ç”Ÿæˆ records
        records = self.process_mean_by_column(df, data_date, first_sheet_name, data_type)

        if not records:
            print("âŒ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆæ•°æ®è¢«å¯¼å…¥")
            return False

        # ä¿å­˜åˆ°æ•°æ®åº“
        return self.save_to_database(records, data_date)

    def process_mean_by_column(self, df, data_date, sheet_name, data_type):
        """
        é’ˆå¯¹èŠ‚ç‚¹ç”µä»·ç­‰è¡¨æ ¼ï¼šå¯¹æ¯ä¸€åˆ—ï¼ˆä»ç¬¬3åˆ—å¼€å§‹ï¼‰æ±‚å‡å€¼ï¼Œå¹¶ç”Ÿæˆè®°å½•
        """
        records = []

        # æ ‡å‡†åŒ–åˆ—å
        df.columns = [str(c).strip() for c in df.columns]

        # è·å–æ—¶é—´åˆ—ï¼ˆç¬¬3åˆ—åŠä¹‹åï¼‰
        time_cols = df.columns[2:]
        if time_cols.empty or len(time_cols) == 0:
            print(f"âš ï¸ Sheet {sheet_name} æ²¡æœ‰å‘ç°æ—¶é—´åˆ—")
            return records

        # å¯¹æ¯åˆ—æ±‚å‡å€¼
        for t in time_cols:
            mean_value = df[t].mean()
            record = {
                "record_date": pd.to_datetime(data_date).date(),
                "record_time": t,              # è¿™é‡Œæ˜¯ "00:00", "00:15" ä¹‹ç±»
                "channel_name": f"{data_type}_å‡å€¼",
                "value": round(mean_value, 2), # è¿™é‡Œæ‰æ˜¯å‡å€¼
                "type": data_type,
                "sheet_name": sheet_name,
                "created_at": pd.Timestamp.now(),
            }
            records.append(record)

        print(f"âœ… {data_type} å‡å€¼ç”Ÿæˆ {len(records)} æ¡è®°å½•")
        return records

